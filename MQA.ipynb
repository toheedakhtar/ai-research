{
 "cells": [
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "de377b57",
   "metadata": {},
   "source": [
    "# MultiQueryAttention - MQA\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "In this, multiple Query heads attend to a single shared key and value heads. \n",
    "sacrifice the ability to capture complex relationship b/w tokens\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d72e92ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d377c3e9",
   "metadata": {},
   "source": [
    "## No KV Cache or Causal Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2dd84659",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiQueryAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super().__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads \n",
    "        self.d_kv = d_model // num_heads\n",
    "\n",
    "        self.W_q = nn.Linear(d_model, d_model, bias=False)\n",
    "\n",
    "        # this will create the single head\n",
    "        self.W_k = nn.Linear(d_model, self.d_kv, bias=False)\n",
    "        self.W_v = nn.Linear(d_model, self.d_kv, bias=False)\n",
    "\n",
    "        # output projection layer\n",
    "        self.W_o = nn.Linear(d_model, d_model, bias=False)\n",
    "    \n",
    "    def forward(self, x): \n",
    "        batch , seq, d_model = x.shape \n",
    "\n",
    "        Q = self.W_q(x) # query matrix\n",
    "        Q = Q.view(batch, seq, self.num_heads, self.d_kv).transpose(1, 2)\n",
    "\n",
    "        K = self.W_k(x)\n",
    "        V = self.W_v(x)\n",
    "\n",
    "        # batch, 1, seq, d_kv - single head\n",
    "        K = K.unsqueeze(1)\n",
    "        V = V.unsqueeze(1)\n",
    "\n",
    "        scores = torch.matmul(Q, K.transpose(-2, -1) / math.sqrt(self.d_kv))\n",
    "        attn_scores = F.softmax(scores, dim=-1)\n",
    "        print(f\"should be 1 if correct: {attn_scores.sum(dim=-1)}\")\n",
    "\n",
    "        attn_weights = torch.matmul(attn_scores , V)\n",
    "        attn_outputs = attn_weights.transpose(1,2).contiguous() # batch, seq, head, d_kv\n",
    "\n",
    "        attn_outputs = attn_outputs.view(batch, seq, d_model)\n",
    "        out = self.W_o(attn_outputs)\n",
    "        print(f\"shape of out : {out.shape}\")\n",
    "\n",
    "        return out\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "761133ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape : torch.Size([2, 10, 64])\n",
      "should be 1 if correct: tensor([[[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "          1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "          1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "          1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "          1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "          1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "          1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "          1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "          1.0000, 1.0000]],\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "          1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "          1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "          1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "          1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "          1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "          1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "          1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "          1.0000, 1.0000]]], grad_fn=<SumBackward1>)\n",
      "shape of out : torch.Size([2, 10, 64])\n"
     ]
    }
   ],
   "source": [
    "batch = 2 \n",
    "seq =  10\n",
    "d_model = 64 \n",
    "num_heads = 8 \n",
    "\n",
    "x = torch.randn(batch, seq, d_model)\n",
    "print(f\"x.shape : {x.shape}\")\n",
    "\n",
    "mqa = MultiQueryAttention(d_model, num_heads)\n",
    "out = mqa(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ebde81",
   "metadata": {},
   "source": [
    "## With KV_Cache\n",
    "kv_cache stores previous Key and Value and only compute for current token. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28d87ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiQueryAttention_V2(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super().__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads \n",
    "        self.d_kv = d_model // num_heads\n",
    "\n",
    "        self.W_q = nn.Linear(d_model, d_model, bias=False)\n",
    "\n",
    "        # this will create the single head\n",
    "        self.W_k = nn.Linear(d_model, self.d_kv, bias=False)\n",
    "        self.W_v = nn.Linear(d_model, self.d_kv, bias=False)\n",
    "\n",
    "        # output projection layer\n",
    "        self.W_o = nn.Linear(d_model, d_model, bias=False)\n",
    "    \n",
    "    def forward(self, x, kv_cache=None, use_kv_cache=False): \n",
    "        batch , seq, d_model = x.shape \n",
    "\n",
    "        Q = self.W_q(x) # query matrix\n",
    "        Q = Q.view(batch, seq, self.num_heads, self.d_kv).transpose(1, 2)\n",
    "\n",
    "        K = self.W_k(x)\n",
    "        V = self.W_v(x)\n",
    "\n",
    "        # batch, 1, seq, d_kv - single head\n",
    "        K = K.unsqueeze(1)\n",
    "        V = V.unsqueeze(1)\n",
    "\n",
    "        if kv_cache is not None:\n",
    "            K = torch.concat([kv_cache[\"k\"], K], dim=2)\n",
    "            V = torch.concat([kv_cache[\"v\"], V], dim=2)\n",
    "        \n",
    "        if use_kv_cache:\n",
    "            new_kv_cache = {\n",
    "                \"k\" : K.detach(), \n",
    "                \"v\" : V.detach()\n",
    "            }\n",
    "        else: \n",
    "            new_kv_cache = None\n",
    "\n",
    "        print(f\"Q shape : {Q.shape}\\nK.shape: {K.shape}\\nV.shape: {V.shape}\")\n",
    "\n",
    "        scores = torch.matmul(Q, K.transpose(-2, -1) / math.sqrt(self.d_kv))\n",
    "        attn_scores = F.softmax(scores, dim=-1)\n",
    "        # print(f\"should be 1 if correct: {attn_scores.sum(dim=-1)}\")\n",
    "\n",
    "        attn_weights = torch.matmul(attn_scores , V)\n",
    "        attn_outputs = attn_weights.transpose(1,2).contiguous() # batch, seq, head, d_kv\n",
    "\n",
    "        attn_outputs = attn_outputs.view(batch, seq, d_model)\n",
    "        out = self.W_o(attn_outputs)\n",
    "        print(f\"shape of out : {out.shape}\")\n",
    "\n",
    "        return out, new_kv_cache\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ae2e7ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape : torch.Size([2, 10, 64])\n",
      "\n",
      "--------------------\n",
      "Q shape : torch.Size([2, 8, 1, 8])\n",
      "K.shape: torch.Size([2, 1, 1, 8])\n",
      "V.shape: torch.Size([2, 1, 1, 8])\n",
      "shape of out : torch.Size([2, 1, 64])\n",
      "\n",
      "--------------------\n",
      "Q shape : torch.Size([2, 8, 1, 8])\n",
      "K.shape: torch.Size([2, 1, 2, 8])\n",
      "V.shape: torch.Size([2, 1, 2, 8])\n",
      "shape of out : torch.Size([2, 1, 64])\n",
      "\n",
      "--------------------\n",
      "Q shape : torch.Size([2, 8, 1, 8])\n",
      "K.shape: torch.Size([2, 1, 3, 8])\n",
      "V.shape: torch.Size([2, 1, 3, 8])\n",
      "shape of out : torch.Size([2, 1, 64])\n",
      "\n",
      "--------------------\n",
      "Q shape : torch.Size([2, 8, 1, 8])\n",
      "K.shape: torch.Size([2, 1, 4, 8])\n",
      "V.shape: torch.Size([2, 1, 4, 8])\n",
      "shape of out : torch.Size([2, 1, 64])\n",
      "\n",
      "--------------------\n",
      "Q shape : torch.Size([2, 8, 1, 8])\n",
      "K.shape: torch.Size([2, 1, 5, 8])\n",
      "V.shape: torch.Size([2, 1, 5, 8])\n",
      "shape of out : torch.Size([2, 1, 64])\n",
      "\n",
      "--------------------\n",
      "Q shape : torch.Size([2, 8, 1, 8])\n",
      "K.shape: torch.Size([2, 1, 6, 8])\n",
      "V.shape: torch.Size([2, 1, 6, 8])\n",
      "shape of out : torch.Size([2, 1, 64])\n",
      "\n",
      "--------------------\n",
      "Q shape : torch.Size([2, 8, 1, 8])\n",
      "K.shape: torch.Size([2, 1, 7, 8])\n",
      "V.shape: torch.Size([2, 1, 7, 8])\n",
      "shape of out : torch.Size([2, 1, 64])\n",
      "\n",
      "--------------------\n",
      "Q shape : torch.Size([2, 8, 1, 8])\n",
      "K.shape: torch.Size([2, 1, 8, 8])\n",
      "V.shape: torch.Size([2, 1, 8, 8])\n",
      "shape of out : torch.Size([2, 1, 64])\n",
      "\n",
      "--------------------\n",
      "Q shape : torch.Size([2, 8, 1, 8])\n",
      "K.shape: torch.Size([2, 1, 9, 8])\n",
      "V.shape: torch.Size([2, 1, 9, 8])\n",
      "shape of out : torch.Size([2, 1, 64])\n",
      "\n",
      "--------------------\n",
      "Q shape : torch.Size([2, 8, 1, 8])\n",
      "K.shape: torch.Size([2, 1, 10, 8])\n",
      "V.shape: torch.Size([2, 1, 10, 8])\n",
      "shape of out : torch.Size([2, 1, 64])\n"
     ]
    }
   ],
   "source": [
    "batch = 2 \n",
    "seq =  10\n",
    "d_model = 64 \n",
    "num_heads = 8 \n",
    "\n",
    "x = torch.randn(batch, seq, d_model)\n",
    "print(f\"x.shape : {x.shape}\")\n",
    "\n",
    "mqa_kv = MultiQueryAttention_V2(d_model, num_heads)\n",
    "kv_cache = None \n",
    "\n",
    "# not ideal , correct implemntation\n",
    "# out , _ = mqa_kv(x)\n",
    "\n",
    "for i in range(seq):\n",
    "    print(f\"\\n--------------------\")\n",
    "    x_token = x[:, i:i+1, :] # batch , 1 , d_model\n",
    "    output, kv_cache = mqa_kv(x_token, kv_cache=kv_cache, use_kv_cache=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525b2308",
   "metadata": {},
   "source": [
    "## with KV Cache and Causal Masking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e954ccd",
   "metadata": {},
   "source": [
    "Demonstrating masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f9515c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1464, -0.6353, -0.4628, -0.7955, -0.0307],\n",
      "        [ 2.5423, -0.6772,  0.7265,  2.2504,  0.6527],\n",
      "        [ 1.1242,  0.2020,  0.9589, -0.2554,  2.1855],\n",
      "        [-0.5736, -0.8683,  0.1676, -0.0050,  0.2687],\n",
      "        [ 1.3856, -0.2750,  1.6399,  0.0066, -0.2922]])\n",
      "\n",
      "tensor([[False,  True,  True,  True,  True],\n",
      "        [False, False,  True,  True,  True],\n",
      "        [False, False, False,  True,  True],\n",
      "        [False, False, False, False,  True],\n",
      "        [False, False, False, False, False]])\n",
      "\n",
      "tensor([[ 0.1464,    -inf,    -inf,    -inf,    -inf],\n",
      "        [ 2.5423, -0.6772,    -inf,    -inf,    -inf],\n",
      "        [ 1.1242,  0.2020,  0.9589,    -inf,    -inf],\n",
      "        [-0.5736, -0.8683,  0.1676, -0.0050,    -inf],\n",
      "        [ 1.3856, -0.2750,  1.6399,  0.0066, -0.2922]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(5,5)\n",
    "print(x)\n",
    "\n",
    "mask = torch.triu(torch.ones(5,5, dtype=torch.bool), diagonal=1)\n",
    "print(f\"\\n{mask}\")\n",
    "\n",
    "masked_x = x.masked_fill(mask, float(\"-inf\"))\n",
    "print(f\"\\n{masked_x}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aa3932b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiQueryAttention_V3(nn.Module):\n",
    "    \"\"\"\n",
    "    with both KV_Cache and cauasl masking in attention\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super().__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads \n",
    "        self.d_kv = d_model // num_heads\n",
    "\n",
    "        self.W_q = nn.Linear(d_model, d_model, bias=False)\n",
    "\n",
    "        # this will create the single head\n",
    "        self.W_k = nn.Linear(d_model, self.d_kv, bias=False)\n",
    "        self.W_v = nn.Linear(d_model, self.d_kv, bias=False)\n",
    "\n",
    "        # output projection layer\n",
    "        self.W_o = nn.Linear(d_model, d_model, bias=False)\n",
    "    \n",
    "    def forward(self, x, kv_cache=None, use_kv_cache=False): \n",
    "        batch , seq, d_model = x.shape \n",
    "\n",
    "        Q = self.W_q(x) # query matrix\n",
    "        Q = Q.view(batch, seq, self.num_heads, self.d_kv).transpose(1, 2)\n",
    "\n",
    "        K = self.W_k(x)\n",
    "        V = self.W_v(x)\n",
    "\n",
    "        # batch, 1, seq, d_kv - single head\n",
    "        K = K.unsqueeze(1)\n",
    "        V = V.unsqueeze(1)\n",
    "        \n",
    "        past_len = 0\n",
    "        if kv_cache is not None:\n",
    "            past_len = kv_cache[\"k\"].shape[2] # seq\n",
    "            K = torch.concat([kv_cache[\"k\"], K], dim=2)\n",
    "            V = torch.concat([kv_cache[\"v\"], V], dim=2)\n",
    "        \n",
    "        if use_kv_cache:\n",
    "            new_kv_cache = {\n",
    "                \"k\" : K.detach(), \n",
    "                \"v\" : V.detach()\n",
    "            }\n",
    "        else: \n",
    "            new_kv_cache = None\n",
    "\n",
    "        print(f\"Q shape : {Q.shape}\\nK.shape: {K.shape}\\nV.shape: {V.shape}\")\n",
    "\n",
    "        scores = torch.matmul(Q, K.transpose(-2, -1) / math.sqrt(self.d_kv))\n",
    "        if seq > 1: # otherwise causal masking wont work\n",
    "            total_len = past_len + seq \n",
    "            scores = scores.masked_fill(torch.triu(torch.ones(seq, total_len, dtype=torch.bool, device=scores.device), diagonal=past_len+1), float(\"-inf\"))\n",
    "                        \n",
    "        attn_scores = F.softmax(scores, dim=-1)\n",
    "        # print(f\"should be 1 if correct: {attn_scores.sum(dim=-1)}\")\n",
    "\n",
    "        attn_weights = torch.matmul(attn_scores , V)\n",
    "        attn_outputs = attn_weights.transpose(1,2).contiguous() # batch, seq, head, d_kv\n",
    "\n",
    "        attn_outputs = attn_outputs.view(batch, seq, d_model)\n",
    "        out = self.W_o(attn_outputs)\n",
    "        print(f\"shape of out : {out.shape}\")\n",
    "\n",
    "        return out, new_kv_cache\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9417313e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape : torch.Size([2, 10, 64])\n",
      "\n",
      "--------------------\n",
      "Q shape : torch.Size([2, 8, 1, 8])\n",
      "K.shape: torch.Size([2, 1, 1, 8])\n",
      "V.shape: torch.Size([2, 1, 1, 8])\n",
      "shape of out : torch.Size([2, 1, 64])\n",
      "\n",
      "--------------------\n",
      "Q shape : torch.Size([2, 8, 1, 8])\n",
      "K.shape: torch.Size([2, 1, 2, 8])\n",
      "V.shape: torch.Size([2, 1, 2, 8])\n",
      "shape of out : torch.Size([2, 1, 64])\n",
      "\n",
      "--------------------\n",
      "Q shape : torch.Size([2, 8, 1, 8])\n",
      "K.shape: torch.Size([2, 1, 3, 8])\n",
      "V.shape: torch.Size([2, 1, 3, 8])\n",
      "shape of out : torch.Size([2, 1, 64])\n",
      "\n",
      "--------------------\n",
      "Q shape : torch.Size([2, 8, 1, 8])\n",
      "K.shape: torch.Size([2, 1, 4, 8])\n",
      "V.shape: torch.Size([2, 1, 4, 8])\n",
      "shape of out : torch.Size([2, 1, 64])\n",
      "\n",
      "--------------------\n",
      "Q shape : torch.Size([2, 8, 1, 8])\n",
      "K.shape: torch.Size([2, 1, 5, 8])\n",
      "V.shape: torch.Size([2, 1, 5, 8])\n",
      "shape of out : torch.Size([2, 1, 64])\n",
      "\n",
      "--------------------\n",
      "Q shape : torch.Size([2, 8, 1, 8])\n",
      "K.shape: torch.Size([2, 1, 6, 8])\n",
      "V.shape: torch.Size([2, 1, 6, 8])\n",
      "shape of out : torch.Size([2, 1, 64])\n",
      "\n",
      "--------------------\n",
      "Q shape : torch.Size([2, 8, 1, 8])\n",
      "K.shape: torch.Size([2, 1, 7, 8])\n",
      "V.shape: torch.Size([2, 1, 7, 8])\n",
      "shape of out : torch.Size([2, 1, 64])\n",
      "\n",
      "--------------------\n",
      "Q shape : torch.Size([2, 8, 1, 8])\n",
      "K.shape: torch.Size([2, 1, 8, 8])\n",
      "V.shape: torch.Size([2, 1, 8, 8])\n",
      "shape of out : torch.Size([2, 1, 64])\n",
      "\n",
      "--------------------\n",
      "Q shape : torch.Size([2, 8, 1, 8])\n",
      "K.shape: torch.Size([2, 1, 9, 8])\n",
      "V.shape: torch.Size([2, 1, 9, 8])\n",
      "shape of out : torch.Size([2, 1, 64])\n",
      "\n",
      "--------------------\n",
      "Q shape : torch.Size([2, 8, 1, 8])\n",
      "K.shape: torch.Size([2, 1, 10, 8])\n",
      "V.shape: torch.Size([2, 1, 10, 8])\n",
      "shape of out : torch.Size([2, 1, 64])\n"
     ]
    }
   ],
   "source": [
    "batch = 2 \n",
    "seq =  10\n",
    "d_model = 64 \n",
    "num_heads = 8 \n",
    "\n",
    "x = torch.randn(batch, seq, d_model)\n",
    "print(f\"x.shape : {x.shape}\")\n",
    "\n",
    "mqa_kv = MultiQueryAttention_V3(d_model, num_heads)\n",
    "kv_cache = None \n",
    "\n",
    "# not ideal , correct implemntation\n",
    "# out , _ = mqa_kv(x)\n",
    "\n",
    "for i in range(seq):\n",
    "    print(f\"\\n--------------------\")\n",
    "    x_token = x[:, i:i+1, :] # batch , 1 , d_model\n",
    "    output, kv_cache = mqa_kv(x_token, kv_cache=kv_cache, use_kv_cache=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38642c8",
   "metadata": {},
   "source": [
    "Thus, have implemented Multi Query Attention. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
