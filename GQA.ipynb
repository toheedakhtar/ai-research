{
 "cells": [
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "0bc29608",
   "metadata": {},
   "source": [
    "# GroupedQueryAttention - GQA\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "similar to MQA but used a set of shared Key and value heads instead of one , for the Query heads  \n",
    "query heads are divided into groups , which share a single key and value head   \n",
    "requires more memory than MQA but gives better performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6d42921",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20be0ca",
   "metadata": {},
   "source": [
    "## without KV_Cache or Causal Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "248df8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GroupedQueryAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, n_kv_heads):\n",
    "        super().__init__()\n",
    "\n",
    "        self.d_model = d_model \n",
    "        self.num_heads = num_heads \n",
    "        self.n_kv_heads = n_kv_heads\n",
    "        self.d_kv = d_model // num_heads  \n",
    "\n",
    "        self.W_q = nn.Linear(d_model, d_model, bias=False)\n",
    "        \n",
    "        # n heads\n",
    "        self.W_k = nn.Linear(d_model, self.n_kv_heads * self.d_kv, bias=False)\n",
    "        self.W_v = nn.Linear(d_model, self.n_kv_heads * self.d_kv, bias=False)\n",
    "\n",
    "        self.W_o = nn.Linear(d_model, d_model, bias=False)\n",
    "\n",
    "    def forward(self, x): \n",
    "        batch, seq, d_model = x.shape\n",
    "\n",
    "        Q = self.W_q(x) # d_model = heads*d_kv\n",
    "        Q = Q.view(batch, seq, self.num_heads, self.d_kv).transpose(1,2)\n",
    "        print(f\"Query shape before groups : {Q.shape}\")\n",
    "\n",
    "        K = self.W_k(x)\n",
    "        V = self.W_v(x)\n",
    "\n",
    "        K = K.view(batch, seq, self.n_kv_heads, self.d_kv).transpose(1,2)\n",
    "        V = V.view(batch, seq, self.n_kv_heads, self.d_kv).transpose(1,2)\n",
    "\n",
    "        n_g = self.num_heads // self.n_kv_heads # query heads per n kv heads\n",
    "        print(f\"query head per kv heads: {n_g}\")\n",
    "\n",
    "        # creating groups in query matrix\n",
    "        Q = Q.view(batch, self.n_kv_heads, n_g, seq, self.d_kv)\n",
    "        print(f\"Q shape after grouping : {Q.shape}\")\n",
    "\n",
    "        scores = torch.einsum(\"b h g n d, b h s d -> b h g n s\", Q, K) # QK^T\n",
    "        print(f\"shape of scores : {scores.shape}\")\n",
    "\n",
    "        attn_scores = F.softmax(scores / math.sqrt(self.d_kv), dim=-1)\n",
    "        print(f\"should be 1 if correct: {attn_scores.sum(dim=-1)}\")\n",
    "\n",
    "        attn_weights = torch.einsum(\"b h g n s, b h s d -> b h g n d\", attn_scores, V) # s summed over to produce n\n",
    "        print(f\"shape of attn weights : {attn_weights.shape}\")\n",
    "\n",
    "        attn_weights = attn_weights.view(batch, self.num_heads, seq, self.d_kv) # merging heads\n",
    "\n",
    "        attn_outputs = attn_weights.transpose(1,2).contiguous()\n",
    "        attn_outputs = attn_outputs.view(batch, seq, d_model)\n",
    "\n",
    "        out = self.W_o(attn_outputs)\n",
    "        print(f\"out shape : {out.shape}\")\n",
    "\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44d2ceeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape : torch.Size([2, 10, 64])\n",
      "Query shape before groups : torch.Size([2, 8, 10, 8])\n",
      "query head per kv heads: 4\n",
      "Q shape after grouping : torch.Size([2, 2, 4, 10, 8])\n",
      "shape of scores : torch.Size([2, 2, 4, 10, 10])\n",
      "should be 1 if correct: tensor([[[[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "           1.0000, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "           1.0000, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "           1.0000, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "           1.0000, 1.0000]],\n",
      "\n",
      "         [[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "           1.0000, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "           1.0000, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "           1.0000, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "           1.0000, 1.0000]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "           1.0000, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "           1.0000, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "           1.0000, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "           1.0000, 1.0000]],\n",
      "\n",
      "         [[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "           1.0000, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "           1.0000, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "           1.0000, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "           1.0000, 1.0000]]]], grad_fn=<SumBackward1>)\n",
      "shape of attn weights : torch.Size([2, 2, 4, 10, 8])\n",
      "out shape : torch.Size([2, 10, 64])\n"
     ]
    }
   ],
   "source": [
    "batch = 2 \n",
    "seq =  10\n",
    "d_model = 64 \n",
    "num_heads = 8\n",
    "num_kv_heads = 2 \n",
    "\n",
    "x = torch.randn(batch, seq, d_model)\n",
    "print(f\"x.shape : {x.shape}\")\n",
    "\n",
    "gqa = GroupedQueryAttention(d_model, num_heads, num_kv_heads)\n",
    "out = gqa(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4884d67",
   "metadata": {},
   "source": [
    "## with KV Cache only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b50e512c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GroupedQueryAttention_V2(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, n_kv_heads):\n",
    "        super().__init__()\n",
    "\n",
    "        self.d_model = d_model \n",
    "        self.num_heads = num_heads \n",
    "        self.n_kv_heads = n_kv_heads\n",
    "        self.d_kv = d_model // num_heads  \n",
    "\n",
    "        self.W_q = nn.Linear(d_model, d_model, bias=False)\n",
    "        \n",
    "        # n heads\n",
    "        self.W_k = nn.Linear(d_model, self.n_kv_heads * self.d_kv, bias=False)\n",
    "        self.W_v = nn.Linear(d_model, self.n_kv_heads * self.d_kv, bias=False)\n",
    "\n",
    "        self.W_o = nn.Linear(d_model, d_model, bias=False)\n",
    "\n",
    "    def forward(self, x, kv_cache=None, use_kv_cache=False): \n",
    "        batch, seq, d_model = x.shape\n",
    "\n",
    "        Q = self.W_q(x) # d_model = heads*d_kv\n",
    "        Q = Q.view(batch, seq, self.num_heads, self.d_kv).transpose(1,2)\n",
    "        # print(f\"Query shape before groups : {Q.shape}\")\n",
    "\n",
    "        K = self.W_k(x)\n",
    "        V = self.W_v(x)\n",
    "\n",
    "        K = K.view(batch, seq, self.n_kv_heads, self.d_kv).transpose(1,2)\n",
    "        V = V.view(batch, seq, self.n_kv_heads, self.d_kv).transpose(1,2)\n",
    "\n",
    "        n_g = self.num_heads // self.n_kv_heads # query heads per n kv heads\n",
    "        print(f\"query head per kv heads: {n_g}\")\n",
    "\n",
    "        # creating groups in query matrix\n",
    "        Q = Q.view(batch, self.n_kv_heads, n_g, seq, self.d_kv)\n",
    "        # print(f\"Q shape after grouping : {Q.shape}\")\n",
    "\n",
    "        if kv_cache is not None:\n",
    "            K = torch.concat([kv_cache[\"k\"], K], dim=2)\n",
    "            V = torch.concat([kv_cache[\"v\"], V], dim=2)\n",
    "        \n",
    "        if use_kv_cache:\n",
    "            new_kv_cache = {\n",
    "                \"k\" : K.detach(),\n",
    "                \"v\" : V.detach(),\n",
    "            }\n",
    "        else:\n",
    "            new_kv_cache = None \n",
    "\n",
    "        print(f\"Q shape : {Q.shape}\\nK shape: {K.shape}\\nV shape {V.shape}\")\n",
    "\n",
    "        scores = torch.einsum(\"b h g n d, b h s d -> b h g n s\", Q, K) # QK^T\n",
    "        # print(f\"shape of scores : {scores.shape}\")\n",
    "\n",
    "        attn_scores = F.softmax(scores / math.sqrt(self.d_kv), dim=-1)\n",
    "        # print(f\"should be 1 if correct: {attn_scores.sum(dim=-1)}\")\n",
    "\n",
    "        attn_weights = torch.einsum(\"b h g n s, b h s d -> b h g n d\", attn_scores, V) # s summed over to produce n\n",
    "        # print(f\"shape of attn weights : {attn_weights.shape}\")\n",
    "\n",
    "        attn_weights = attn_weights.view(batch, self.num_heads, seq, self.d_kv) # merging heads\n",
    "\n",
    "        attn_outputs = attn_weights.transpose(1,2).contiguous()\n",
    "        attn_outputs = attn_outputs.view(batch, seq, d_model)\n",
    "\n",
    "        out = self.W_o(attn_outputs)\n",
    "        print(f\"out shape : {out.shape}\")\n",
    "\n",
    "        return out, new_kv_cache\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e27b2c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape : torch.Size([2, 10, 64])\n",
      "\n",
      "--------------------\n",
      "query head per kv heads: 4\n",
      "Q shape : torch.Size([2, 2, 4, 1, 8])\n",
      "K shape: torch.Size([2, 2, 1, 8])\n",
      "V shape torch.Size([2, 2, 1, 8])\n",
      "out shape : torch.Size([2, 1, 64])\n",
      "\n",
      "--------------------\n",
      "query head per kv heads: 4\n",
      "Q shape : torch.Size([2, 2, 4, 1, 8])\n",
      "K shape: torch.Size([2, 2, 2, 8])\n",
      "V shape torch.Size([2, 2, 2, 8])\n",
      "out shape : torch.Size([2, 1, 64])\n",
      "\n",
      "--------------------\n",
      "query head per kv heads: 4\n",
      "Q shape : torch.Size([2, 2, 4, 1, 8])\n",
      "K shape: torch.Size([2, 2, 3, 8])\n",
      "V shape torch.Size([2, 2, 3, 8])\n",
      "out shape : torch.Size([2, 1, 64])\n",
      "\n",
      "--------------------\n",
      "query head per kv heads: 4\n",
      "Q shape : torch.Size([2, 2, 4, 1, 8])\n",
      "K shape: torch.Size([2, 2, 4, 8])\n",
      "V shape torch.Size([2, 2, 4, 8])\n",
      "out shape : torch.Size([2, 1, 64])\n",
      "\n",
      "--------------------\n",
      "query head per kv heads: 4\n",
      "Q shape : torch.Size([2, 2, 4, 1, 8])\n",
      "K shape: torch.Size([2, 2, 5, 8])\n",
      "V shape torch.Size([2, 2, 5, 8])\n",
      "out shape : torch.Size([2, 1, 64])\n",
      "\n",
      "--------------------\n",
      "query head per kv heads: 4\n",
      "Q shape : torch.Size([2, 2, 4, 1, 8])\n",
      "K shape: torch.Size([2, 2, 6, 8])\n",
      "V shape torch.Size([2, 2, 6, 8])\n",
      "out shape : torch.Size([2, 1, 64])\n",
      "\n",
      "--------------------\n",
      "query head per kv heads: 4\n",
      "Q shape : torch.Size([2, 2, 4, 1, 8])\n",
      "K shape: torch.Size([2, 2, 7, 8])\n",
      "V shape torch.Size([2, 2, 7, 8])\n",
      "out shape : torch.Size([2, 1, 64])\n",
      "\n",
      "--------------------\n",
      "query head per kv heads: 4\n",
      "Q shape : torch.Size([2, 2, 4, 1, 8])\n",
      "K shape: torch.Size([2, 2, 8, 8])\n",
      "V shape torch.Size([2, 2, 8, 8])\n",
      "out shape : torch.Size([2, 1, 64])\n",
      "\n",
      "--------------------\n",
      "query head per kv heads: 4\n",
      "Q shape : torch.Size([2, 2, 4, 1, 8])\n",
      "K shape: torch.Size([2, 2, 9, 8])\n",
      "V shape torch.Size([2, 2, 9, 8])\n",
      "out shape : torch.Size([2, 1, 64])\n",
      "\n",
      "--------------------\n",
      "query head per kv heads: 4\n",
      "Q shape : torch.Size([2, 2, 4, 1, 8])\n",
      "K shape: torch.Size([2, 2, 10, 8])\n",
      "V shape torch.Size([2, 2, 10, 8])\n",
      "out shape : torch.Size([2, 1, 64])\n"
     ]
    }
   ],
   "source": [
    "batch = 2 \n",
    "seq =  10\n",
    "d_model = 64 \n",
    "num_heads = 8\n",
    "num_kv_heads = 2 \n",
    "\n",
    "x = torch.randn(batch, seq, d_model)\n",
    "print(f\"x.shape : {x.shape}\")\n",
    "\n",
    "gqa_v2 = GroupedQueryAttention_V2(d_model, num_heads, num_kv_heads)\n",
    "# out = gqa_v2(x)\n",
    "\n",
    "kv_cache = None\n",
    "for i in range(seq):\n",
    "    print(f\"\\n--------------------\")\n",
    "    x_token = x[:, i:i+1, :] # batch , 1 , d_model\n",
    "    output, kv_cache = gqa_v2(x_token, kv_cache=kv_cache, use_kv_cache=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f711bee2",
   "metadata": {},
   "source": [
    "## with both KV Cache and causal masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b0389b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GroupedQueryAttention_V3(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, n_kv_heads):\n",
    "        super().__init__()\n",
    "\n",
    "        self.d_model = d_model \n",
    "        self.num_heads = num_heads \n",
    "        self.n_kv_heads = n_kv_heads\n",
    "        self.d_kv = d_model // num_heads  \n",
    "\n",
    "        self.W_q = nn.Linear(d_model, d_model, bias=False)\n",
    "        \n",
    "        # n heads\n",
    "        self.W_k = nn.Linear(d_model, self.n_kv_heads * self.d_kv, bias=False)\n",
    "        self.W_v = nn.Linear(d_model, self.n_kv_heads * self.d_kv, bias=False)\n",
    "\n",
    "        self.W_o = nn.Linear(d_model, d_model, bias=False)\n",
    "\n",
    "    def forward(self, x, kv_cache=None, use_kv_cache=False): \n",
    "        batch, seq, d_model = x.shape\n",
    "\n",
    "        Q = self.W_q(x) # d_model = heads*d_kv\n",
    "        Q = Q.view(batch, seq, self.num_heads, self.d_kv).transpose(1,2)\n",
    "        # print(f\"Query shape before groups : {Q.shape}\")\n",
    "\n",
    "        K = self.W_k(x)\n",
    "        V = self.W_v(x)\n",
    "\n",
    "        K = K.view(batch, seq, self.n_kv_heads, self.d_kv).transpose(1,2)\n",
    "        V = V.view(batch, seq, self.n_kv_heads, self.d_kv).transpose(1,2)\n",
    "\n",
    "        n_g = self.num_heads // self.n_kv_heads # query heads per n kv heads\n",
    "        print(f\"query head per kv heads: {n_g}\")\n",
    "\n",
    "        # creating groups in query matrix\n",
    "        Q = Q.view(batch, self.n_kv_heads, n_g, seq, self.d_kv)\n",
    "        # print(f\"Q shape after grouping : {Q.shape}\")\n",
    "\n",
    "        past_len = 0\n",
    "        if kv_cache is not None:\n",
    "            K = torch.concat([kv_cache[\"k\"], K], dim=2)\n",
    "            V = torch.concat([kv_cache[\"v\"], V], dim=2)\n",
    "            past_len = kv_cache[\"k\"].shape[2]\n",
    "        \n",
    "        if use_kv_cache:\n",
    "            new_kv_cache = {\n",
    "                \"k\" : K.detach(),\n",
    "                \"v\" : V.detach(),\n",
    "            }\n",
    "        else:\n",
    "            new_kv_cache = None \n",
    "\n",
    "        print(f\"Q shape : {Q.shape}\\nK shape: {K.shape}\\nV shape {V.shape}\")\n",
    "\n",
    "        scores = torch.einsum(\"b h g n d, b h s d -> b h g n s\", Q, K) # QK^T\n",
    "        if seq > 1:\n",
    "            total_len = past_len+seq \n",
    "            scores = scores.masked_fill(torch.triu(torch.ones(seq, total_len, dtype=torch.bool, device=scores.device), diagonal=past_len+1), float(\"-inf\"))\n",
    "        # print(f\"shape of scores : {scores.shape}\")\n",
    "\n",
    "        attn_scores = F.softmax(scores / math.sqrt(self.d_kv), dim=-1)\n",
    "        print(f\"should be 1 if correct: {attn_scores.sum(dim=-1)}\")\n",
    "\n",
    "        attn_weights = torch.einsum(\"b h g n s, b h s d -> b h g n d\", attn_scores, V) # s summed over to produce n\n",
    "        print(f\"shape of attn weights : {attn_weights.shape}\")\n",
    "\n",
    "        attn_weights = attn_weights.view(batch, self.num_heads, seq, self.d_kv) # merging heads\n",
    "\n",
    "        attn_outputs = attn_weights.transpose(1,2).contiguous()\n",
    "        attn_outputs = attn_outputs.view(batch, seq, d_model)\n",
    "\n",
    "        out = self.W_o(attn_outputs)\n",
    "        print(f\"out shape : {out.shape}\")\n",
    "\n",
    "        return out, new_kv_cache\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fdb641e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape : torch.Size([2, 10, 64])\n",
      "query head per kv heads: 4\n",
      "Q shape : torch.Size([2, 2, 4, 10, 8])\n",
      "K shape: torch.Size([2, 2, 10, 8])\n",
      "V shape torch.Size([2, 2, 10, 8])\n",
      "should be 1 if correct: tensor([[[[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "           1.0000, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "           1.0000, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "           1.0000, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "           1.0000, 1.0000]],\n",
      "\n",
      "         [[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "           1.0000, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "           1.0000, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "           1.0000, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "           1.0000, 1.0000]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "           1.0000, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "           1.0000, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "           1.0000, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "           1.0000, 1.0000]],\n",
      "\n",
      "         [[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "           1.0000, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "           1.0000, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "           1.0000, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "           1.0000, 1.0000]]]], grad_fn=<SumBackward1>)\n",
      "shape of attn weights : torch.Size([2, 2, 4, 10, 8])\n",
      "out shape : torch.Size([2, 10, 64])\n",
      "\n",
      "--------------------\n",
      "query head per kv heads: 4\n",
      "Q shape : torch.Size([2, 2, 4, 1, 8])\n",
      "K shape: torch.Size([2, 2, 1, 8])\n",
      "V shape torch.Size([2, 2, 1, 8])\n",
      "should be 1 if correct: tensor([[[[1.],\n",
      "          [1.],\n",
      "          [1.],\n",
      "          [1.]],\n",
      "\n",
      "         [[1.],\n",
      "          [1.],\n",
      "          [1.],\n",
      "          [1.]]],\n",
      "\n",
      "\n",
      "        [[[1.],\n",
      "          [1.],\n",
      "          [1.],\n",
      "          [1.]],\n",
      "\n",
      "         [[1.],\n",
      "          [1.],\n",
      "          [1.],\n",
      "          [1.]]]], grad_fn=<SumBackward1>)\n",
      "shape of attn weights : torch.Size([2, 2, 4, 1, 8])\n",
      "out shape : torch.Size([2, 1, 64])\n",
      "\n",
      "--------------------\n",
      "query head per kv heads: 4\n",
      "Q shape : torch.Size([2, 2, 4, 1, 8])\n",
      "K shape: torch.Size([2, 2, 2, 8])\n",
      "V shape torch.Size([2, 2, 2, 8])\n",
      "should be 1 if correct: tensor([[[[1.0000],\n",
      "          [1.0000],\n",
      "          [1.0000],\n",
      "          [1.0000]],\n",
      "\n",
      "         [[1.0000],\n",
      "          [1.0000],\n",
      "          [1.0000],\n",
      "          [1.0000]]],\n",
      "\n",
      "\n",
      "        [[[1.0000],\n",
      "          [1.0000],\n",
      "          [1.0000],\n",
      "          [1.0000]],\n",
      "\n",
      "         [[1.0000],\n",
      "          [1.0000],\n",
      "          [1.0000],\n",
      "          [1.0000]]]], grad_fn=<SumBackward1>)\n",
      "shape of attn weights : torch.Size([2, 2, 4, 1, 8])\n",
      "out shape : torch.Size([2, 1, 64])\n",
      "\n",
      "--------------------\n",
      "query head per kv heads: 4\n",
      "Q shape : torch.Size([2, 2, 4, 1, 8])\n",
      "K shape: torch.Size([2, 2, 3, 8])\n",
      "V shape torch.Size([2, 2, 3, 8])\n",
      "should be 1 if correct: tensor([[[[1.0000],\n",
      "          [1.0000],\n",
      "          [1.0000],\n",
      "          [1.0000]],\n",
      "\n",
      "         [[1.0000],\n",
      "          [1.0000],\n",
      "          [1.0000],\n",
      "          [1.0000]]],\n",
      "\n",
      "\n",
      "        [[[1.0000],\n",
      "          [1.0000],\n",
      "          [1.0000],\n",
      "          [1.0000]],\n",
      "\n",
      "         [[1.0000],\n",
      "          [1.0000],\n",
      "          [1.0000],\n",
      "          [1.0000]]]], grad_fn=<SumBackward1>)\n",
      "shape of attn weights : torch.Size([2, 2, 4, 1, 8])\n",
      "out shape : torch.Size([2, 1, 64])\n",
      "\n",
      "--------------------\n",
      "query head per kv heads: 4\n",
      "Q shape : torch.Size([2, 2, 4, 1, 8])\n",
      "K shape: torch.Size([2, 2, 4, 8])\n",
      "V shape torch.Size([2, 2, 4, 8])\n",
      "should be 1 if correct: tensor([[[[1.0000],\n",
      "          [1.0000],\n",
      "          [1.0000],\n",
      "          [1.0000]],\n",
      "\n",
      "         [[1.0000],\n",
      "          [1.0000],\n",
      "          [1.0000],\n",
      "          [1.0000]]],\n",
      "\n",
      "\n",
      "        [[[1.0000],\n",
      "          [1.0000],\n",
      "          [1.0000],\n",
      "          [1.0000]],\n",
      "\n",
      "         [[1.0000],\n",
      "          [1.0000],\n",
      "          [1.0000],\n",
      "          [1.0000]]]], grad_fn=<SumBackward1>)\n",
      "shape of attn weights : torch.Size([2, 2, 4, 1, 8])\n",
      "out shape : torch.Size([2, 1, 64])\n",
      "\n",
      "--------------------\n",
      "query head per kv heads: 4\n",
      "Q shape : torch.Size([2, 2, 4, 1, 8])\n",
      "K shape: torch.Size([2, 2, 5, 8])\n",
      "V shape torch.Size([2, 2, 5, 8])\n",
      "should be 1 if correct: tensor([[[[1.0000],\n",
      "          [1.0000],\n",
      "          [1.0000],\n",
      "          [1.0000]],\n",
      "\n",
      "         [[1.0000],\n",
      "          [1.0000],\n",
      "          [1.0000],\n",
      "          [1.0000]]],\n",
      "\n",
      "\n",
      "        [[[1.0000],\n",
      "          [1.0000],\n",
      "          [1.0000],\n",
      "          [1.0000]],\n",
      "\n",
      "         [[1.0000],\n",
      "          [1.0000],\n",
      "          [1.0000],\n",
      "          [1.0000]]]], grad_fn=<SumBackward1>)\n",
      "shape of attn weights : torch.Size([2, 2, 4, 1, 8])\n",
      "out shape : torch.Size([2, 1, 64])\n",
      "\n",
      "--------------------\n",
      "query head per kv heads: 4\n",
      "Q shape : torch.Size([2, 2, 4, 1, 8])\n",
      "K shape: torch.Size([2, 2, 6, 8])\n",
      "V shape torch.Size([2, 2, 6, 8])\n",
      "should be 1 if correct: tensor([[[[1.0000],\n",
      "          [1.0000],\n",
      "          [1.0000],\n",
      "          [1.0000]],\n",
      "\n",
      "         [[1.0000],\n",
      "          [1.0000],\n",
      "          [1.0000],\n",
      "          [1.0000]]],\n",
      "\n",
      "\n",
      "        [[[1.0000],\n",
      "          [1.0000],\n",
      "          [1.0000],\n",
      "          [1.0000]],\n",
      "\n",
      "         [[1.0000],\n",
      "          [1.0000],\n",
      "          [1.0000],\n",
      "          [1.0000]]]], grad_fn=<SumBackward1>)\n",
      "shape of attn weights : torch.Size([2, 2, 4, 1, 8])\n",
      "out shape : torch.Size([2, 1, 64])\n",
      "\n",
      "--------------------\n",
      "query head per kv heads: 4\n",
      "Q shape : torch.Size([2, 2, 4, 1, 8])\n",
      "K shape: torch.Size([2, 2, 7, 8])\n",
      "V shape torch.Size([2, 2, 7, 8])\n",
      "should be 1 if correct: tensor([[[[1.0000],\n",
      "          [1.0000],\n",
      "          [1.0000],\n",
      "          [1.0000]],\n",
      "\n",
      "         [[1.0000],\n",
      "          [1.0000],\n",
      "          [1.0000],\n",
      "          [1.0000]]],\n",
      "\n",
      "\n",
      "        [[[1.0000],\n",
      "          [1.0000],\n",
      "          [1.0000],\n",
      "          [1.0000]],\n",
      "\n",
      "         [[1.0000],\n",
      "          [1.0000],\n",
      "          [1.0000],\n",
      "          [1.0000]]]], grad_fn=<SumBackward1>)\n",
      "shape of attn weights : torch.Size([2, 2, 4, 1, 8])\n",
      "out shape : torch.Size([2, 1, 64])\n",
      "\n",
      "--------------------\n",
      "query head per kv heads: 4\n",
      "Q shape : torch.Size([2, 2, 4, 1, 8])\n",
      "K shape: torch.Size([2, 2, 8, 8])\n",
      "V shape torch.Size([2, 2, 8, 8])\n",
      "should be 1 if correct: tensor([[[[1.0000],\n",
      "          [1.0000],\n",
      "          [1.0000],\n",
      "          [1.0000]],\n",
      "\n",
      "         [[1.0000],\n",
      "          [1.0000],\n",
      "          [1.0000],\n",
      "          [1.0000]]],\n",
      "\n",
      "\n",
      "        [[[1.0000],\n",
      "          [1.0000],\n",
      "          [1.0000],\n",
      "          [1.0000]],\n",
      "\n",
      "         [[1.0000],\n",
      "          [1.0000],\n",
      "          [1.0000],\n",
      "          [1.0000]]]], grad_fn=<SumBackward1>)\n",
      "shape of attn weights : torch.Size([2, 2, 4, 1, 8])\n",
      "out shape : torch.Size([2, 1, 64])\n",
      "\n",
      "--------------------\n",
      "query head per kv heads: 4\n",
      "Q shape : torch.Size([2, 2, 4, 1, 8])\n",
      "K shape: torch.Size([2, 2, 9, 8])\n",
      "V shape torch.Size([2, 2, 9, 8])\n",
      "should be 1 if correct: tensor([[[[1.0000],\n",
      "          [1.0000],\n",
      "          [1.0000],\n",
      "          [1.0000]],\n",
      "\n",
      "         [[1.0000],\n",
      "          [1.0000],\n",
      "          [1.0000],\n",
      "          [1.0000]]],\n",
      "\n",
      "\n",
      "        [[[1.0000],\n",
      "          [1.0000],\n",
      "          [1.0000],\n",
      "          [1.0000]],\n",
      "\n",
      "         [[1.0000],\n",
      "          [1.0000],\n",
      "          [1.0000],\n",
      "          [1.0000]]]], grad_fn=<SumBackward1>)\n",
      "shape of attn weights : torch.Size([2, 2, 4, 1, 8])\n",
      "out shape : torch.Size([2, 1, 64])\n",
      "\n",
      "--------------------\n",
      "query head per kv heads: 4\n",
      "Q shape : torch.Size([2, 2, 4, 1, 8])\n",
      "K shape: torch.Size([2, 2, 10, 8])\n",
      "V shape torch.Size([2, 2, 10, 8])\n",
      "should be 1 if correct: tensor([[[[1.0000],\n",
      "          [1.0000],\n",
      "          [1.0000],\n",
      "          [1.0000]],\n",
      "\n",
      "         [[1.0000],\n",
      "          [1.0000],\n",
      "          [1.0000],\n",
      "          [1.0000]]],\n",
      "\n",
      "\n",
      "        [[[1.0000],\n",
      "          [1.0000],\n",
      "          [1.0000],\n",
      "          [1.0000]],\n",
      "\n",
      "         [[1.0000],\n",
      "          [1.0000],\n",
      "          [1.0000],\n",
      "          [1.0000]]]], grad_fn=<SumBackward1>)\n",
      "shape of attn weights : torch.Size([2, 2, 4, 1, 8])\n",
      "out shape : torch.Size([2, 1, 64])\n"
     ]
    }
   ],
   "source": [
    "batch = 2 \n",
    "seq =  10\n",
    "d_model = 64 \n",
    "num_heads = 8\n",
    "num_kv_heads = 2 \n",
    "\n",
    "x = torch.randn(batch, seq, d_model)\n",
    "print(f\"x.shape : {x.shape}\")\n",
    "\n",
    "gqa_v3 = GroupedQueryAttention_V3(d_model, num_heads, num_kv_heads)\n",
    "out = gqa_v3(x)\n",
    "\n",
    "kv_cache = None\n",
    "for i in range(seq):\n",
    "    print(f\"\\n--------------------\")\n",
    "    x_token = x[:, i:i+1, :] # batch , 1 , d_model\n",
    "    output, kv_cache = gqa_v3(x_token, kv_cache=kv_cache, use_kv_cache=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6a3eca",
   "metadata": {},
   "source": [
    "Thus, have implemented Grouped Query Attention with Kv Cache and masking"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
